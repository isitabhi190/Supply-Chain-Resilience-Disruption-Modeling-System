{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd440c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ADVANCED Supply Chain Resilience & Disruption Modeling System\n",
    "Enterprise-Grade Implementation with Advanced Analytics\n",
    "\n",
    "NEW FEATURES:\n",
    "- Multi-objective optimization (cost vs service level)\n",
    "- Time-series forecasting with ARIMA/Prophet\n",
    "- Network graph analysis for supply chain topology\n",
    "- Monte Carlo simulation for risk quantification\n",
    "- Scenario analysis (what-if modeling)\n",
    "- A/B testing framework for strategy validation\n",
    "- Real-time anomaly detection\n",
    "- Supplier diversification recommendations\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML & Advanced Analytics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "\n",
    "# Network Analysis\n",
    "import networkx as nx\n",
    "\n",
    "# Time Series (if available - will gracefully handle if not installed)\n",
    "try:\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "    from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "    TIMESERIES_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TIMESERIES_AVAILABLE = False\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 1: DATA INGESTION, MAPPING & NETWORK TOPOLOGY\n",
    "# ============================================================================\n",
    "\n",
    "class AdvancedSupplyChainDataEngineer:\n",
    "    \"\"\"Handles Kaggle data loading, mapping, and network analysis\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.network = None\n",
    "        \n",
    "    def load_and_map_data(self, file_path):\n",
    "        \"\"\"Loads the CSV from Kaggle path and maps columns to system standards\"\"\"\n",
    "        print(f\"\\nüìÇ Loading dataset from Kaggle: {file_path}\")\n",
    "        \n",
    "        # Load the raw data\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # 1. Map your specific CSV columns to the system's required names\n",
    "        # We map Buyer_ID to Country and Organization_ID to Warehouse to maintain \n",
    "        # the geographical/structural logic of the network.\n",
    "        mapping = {\n",
    "            'Buyer_ID': 'Destination_Country',\n",
    "            'Organization_ID': 'Origin_Warehouse', \n",
    "            'Quantity_Ordered': 'Order_Quantity',\n",
    "            'Order_Value_USD': 'Sales_Value',\n",
    "            'Supply_Risk_Flag': 'Delivery_Status'\n",
    "        }\n",
    "        df = df.rename(columns=mapping)\n",
    "        \n",
    "        # 2. Temporal Data Processing\n",
    "        df['Order_Date'] = pd.to_datetime(df['Order_Date'])\n",
    "        df['Delivery_Date'] = pd.to_datetime(df['Delivery_Date'])\n",
    "        \n",
    "        # Calculate real lead time in days\n",
    "        df['Days_Real'] = (df['Delivery_Date'] - df['Order_Date']).dt.days.clip(lower=1)\n",
    "        \n",
    "        # Calculate scheduled days by subtracting your 'Delay_Days' from 'Days_Real'\n",
    "        df['Days_Scheduled'] = (df['Days_Real'] - df['Delay_Days']).clip(lower=1)\n",
    "        \n",
    "        # 3. Fill missing fields required for subsequent modeling\n",
    "        if 'Transport_Cost' not in df.columns:\n",
    "            # Estimate freight as 8% of value adjusted by Shipping Mode\n",
    "            mode_multiplier = {'Rail': 1.1, 'Road': 1.0, 'Air': 2.5, 'Sea': 0.7}\n",
    "            df['Transport_Cost'] = df['Sales_Value'] * 0.08 * df['Shipping_Mode'].map(mode_multiplier).fillna(1.0)\n",
    "            \n",
    "        if 'Benefit_per_Order' not in df.columns:\n",
    "            df['Benefit_per_Order'] = df['Sales_Value'] * 0.25 # Assuming a 25% margin\n",
    "            \n",
    "        if 'Unit_Price' not in df.columns:\n",
    "            df['Unit_Price'] = df['Sales_Value'] / (df['Order_Quantity'] + 1)\n",
    "            \n",
    "        if 'Customer_Priority' not in df.columns:\n",
    "            # Leverage your 'Dominant_Buyer_Flag' to assign priority\n",
    "            df['Customer_Priority'] = df['Dominant_Buyer_Flag'].map({1: 'Enterprise', 0: 'Standard'})\n",
    "            \n",
    "        self.data = df\n",
    "        print(f\"‚úì Successfully mapped {len(df):,} records from Kaggle source.\")\n",
    "        return self.data\n",
    "\n",
    "    def build_supply_chain_network(self):\n",
    "        \"\"\"Builds a directed graph: Supplier -> Organization -> Buyer\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"SUPPLY CHAIN NETWORK TOPOLOGY ANALYSIS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        # Edges from Supplier to the Internal Organization (Warehouse)\n",
    "        sw = self.data.groupby(['Supplier_ID', 'Origin_Warehouse']).size().reset_index(name='weight')\n",
    "        for _, row in sw.iterrows():\n",
    "            G.add_edge(row['Supplier_ID'], row['Origin_Warehouse'], weight=row['weight'])\n",
    "            \n",
    "        # Edges from the Organization to the Final Buyer (Destination)\n",
    "        wc = self.data.groupby(['Origin_Warehouse', 'Destination_Country']).size().reset_index(name='weight')\n",
    "        for _, row in wc.iterrows():\n",
    "            G.add_edge(row['Origin_Warehouse'], row['Destination_Country'], weight=row['weight'])\n",
    "            \n",
    "        self.network = G\n",
    "        print(f\"üìä Network Map Created: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "        return G\n",
    "\n",
    "    def engineer_advanced_features(self):\n",
    "        \"\"\"Generates the 30+ features required for the predictive models\"\"\"\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        # Temporal Features\n",
    "        df['Month'] = df['Order_Date'].dt.month\n",
    "        df['Quarter'] = df['Order_Date'].dt.quarter\n",
    "        df['Day_of_Week'] = df['Order_Date'].dt.dayofweek\n",
    "        df['Is_Peak_Season'] = df['Quarter'].isin([4]).astype(int)\n",
    "        df['Is_Winter'] = df['Month'].isin([12, 1, 2]).astype(int)\n",
    "        \n",
    "        # Volatility & Historical Risk Scores\n",
    "        df['Route_Volatility'] = df.groupby(['Destination_Country', 'Shipping_Mode'])['Days_Real'].transform('std').fillna(0)\n",
    "        df['Country_Risk_Score'] = df.groupby('Destination_Country')['Delivery_Status'].transform('mean')\n",
    "        df['Mode_Risk_Score'] = df.groupby('Shipping_Mode')['Delivery_Status'].transform('mean')\n",
    "        df['Supplier_Risk_Score'] = df.groupby('Supplier_ID')['Delivery_Status'].transform('mean')\n",
    "        \n",
    "        # Sort for rolling window calculations\n",
    "        df = df.sort_values('Order_Date')\n",
    "        df['MA_30_Delay_Rate'] = df.groupby('Destination_Country')['Delivery_Status'].transform(lambda x: x.rolling(30, 1).mean())\n",
    "        df['MA_90_Delay_Rate'] = df.groupby('Destination_Country')['Delivery_Status'].transform(lambda x: x.rolling(90, 1).mean())\n",
    "        df['EMA_Delay'] = df.groupby('Destination_Country')['Days_Real'].transform(lambda x: x.ewm(span=20).mean())\n",
    "        \n",
    "        # Interaction Ratios\n",
    "        df['Value_Quantity_Ratio'] = df['Sales_Value'] / (df['Order_Quantity'] + 1)\n",
    "        df['Cost_Benefit_Ratio'] = df['Transport_Cost'] / (df['Benefit_per_Order'] + 1)\n",
    "        df['Priority_Risk'] = df['Customer_Priority'].map({'Standard': 1, 'Premium': 2, 'Enterprise': 3}).fillna(1)\n",
    "        \n",
    "        # Centrality metrics from the network\n",
    "        if self.network:\n",
    "            bc = nx.betweenness_centrality(self.network)\n",
    "            df['Supplier_Centrality'] = df['Supplier_ID'].map(bc).fillna(0)\n",
    "            df['Warehouse_Centrality'] = df['Origin_Warehouse'].map(bc).fillna(0)\n",
    "            \n",
    "        self.data = df\n",
    "        return df\n",
    "\n",
    "    def detect_anomalies(self):\n",
    "        \"\"\"Identifies outlier shipments using Isolation Forest\"\"\"\n",
    "        from sklearn.ensemble import IsolationForest\n",
    "        # We focus on real lead time and value for anomaly detection\n",
    "        features = ['Days_Real', 'Sales_Value', 'Transport_Cost']\n",
    "        iso = IsolationForest(contamination=0.05, random_state=42)\n",
    "        self.data['Is_Anomaly'] = iso.fit_predict(self.data[features].fillna(0))\n",
    "        self.data['Is_Anomaly'] = (self.data['Is_Anomaly'] == -1).astype(int)\n",
    "        return self.data[self.data['Is_Anomaly'] == 1]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 2: ADVANCED PREDICTIVE MODELING & TIME SERIES\n",
    "# ============================================================================\n",
    "\n",
    "class AdvancedPredictiveModeling:\n",
    "    \"\"\"Enhanced ML with ensemble methods, hyperparameter tuning, and forecasting\"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.model = None\n",
    "        self.best_params = None\n",
    "        self.feature_importance = None\n",
    "        self.forecast_results = None\n",
    "        \n",
    "    def prepare_modeling_data(self):\n",
    "        \"\"\"Prepare comprehensive feature set\"\"\"\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        # Feature selection\n",
    "        feature_cols = ['Destination_Country', 'Shipping_Mode', 'Product_Category', 'Supplier_ID',\n",
    "                       'Days_Scheduled', 'Order_Quantity', 'Sales_Value', 'Transport_Cost',\n",
    "                       'Route_Volatility', 'Country_Risk_Score', 'Mode_Risk_Score', \n",
    "                       'Supplier_Risk_Score', 'Month', 'Quarter', 'Day_of_Week',\n",
    "                       'Is_Peak_Season', 'Is_Winter', 'MA_30_Delay_Rate', 'MA_90_Delay_Rate',\n",
    "                       'Value_Quantity_Ratio', 'Cost_Benefit_Ratio', 'Priority_Risk', 'EMA_Delay']\n",
    "        \n",
    "        if 'Supplier_Centrality' in df.columns:\n",
    "            feature_cols.extend(['Supplier_Centrality', 'Warehouse_Centrality'])\n",
    "        \n",
    "        X = df[feature_cols].copy()\n",
    "        y = df['Delivery_Status']\n",
    "        \n",
    "        # Encode categoricals\n",
    "        label_encoders = {}\n",
    "        for col in ['Destination_Country', 'Shipping_Mode', 'Product_Category', 'Supplier_ID']:\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "        \n",
    "        # Handle any remaining nulls\n",
    "        X = X.fillna(X.median())\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"ADVANCED MODELING DATA PREPARATION\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Training set: {len(self.X_train):,} | Test set: {len(self.X_test):,}\")\n",
    "        print(f\"Features: {len(feature_cols)} advanced features\")\n",
    "        print(f\"Class imbalance: {y.mean()*100:.2f}% delays\")\n",
    "        \n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "    \n",
    "    def train_with_hyperparameter_tuning(self):\n",
    "        \"\"\"GridSearchCV for optimal hyperparameters\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"HYPERPARAMETER OPTIMIZATION (GridSearchCV)\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [4, 6, 8],\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'subsample': [0.8, 0.9],\n",
    "            'colsample_bytree': [0.8, 0.9]\n",
    "        }\n",
    "        \n",
    "        xgb = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "        \n",
    "        print(\"\\n‚öôÔ∏è  Running grid search with 3-fold cross-validation...\")\n",
    "        print(f\"   Testing {np.prod([len(v) for v in param_grid.values()])} combinations\")\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            xgb, param_grid, cv=3, scoring='roc_auc', n_jobs=-1, verbose=0\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        self.model = grid_search.best_estimator_\n",
    "        self.best_params = grid_search.best_params_\n",
    "        \n",
    "        print(f\"\\n‚úì Optimization complete!\")\n",
    "        print(f\"  Best CV ROC-AUC: {grid_search.best_score_:.4f}\")\n",
    "        print(f\"  Best parameters: {self.best_params}\")\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def advanced_model_evaluation(self):\n",
    "        \"\"\"Comprehensive evaluation with multiple metrics\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"ADVANCED MODEL PERFORMANCE ANALYSIS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "        y_pred_proba = self.model.predict_proba(self.X_test)[:, 1]\n",
    "        \n",
    "        # Classification metrics\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(self.y_test, y_pred, target_names=['On-Time', 'Late']))\n",
    "        \n",
    "        # ROC-AUC\n",
    "        roc_auc = roc_auc_score(self.y_test, y_pred_proba)\n",
    "        print(f\"\\nROC-AUC Score: {roc_auc:.4f}\")\n",
    "        \n",
    "        # Feature importance\n",
    "        self.feature_importance = pd.DataFrame({\n",
    "            'Feature': self.X_train.columns,\n",
    "            'Importance': self.model.feature_importances_\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        \n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(\"TOP 15 PREDICTIVE FEATURES\")\n",
    "        print(\"-\" * 80)\n",
    "        print(self.feature_importance.head(15).to_string(index=False))\n",
    "        \n",
    "        # Prediction confidence analysis\n",
    "        high_confidence = np.sum((y_pred_proba < 0.3) | (y_pred_proba > 0.7))\n",
    "        print(f\"\\nüìä Prediction Confidence:\")\n",
    "        print(f\"   High confidence predictions: {high_confidence}/{len(y_pred_proba)} ({high_confidence/len(y_pred_proba)*100:.1f}%)\")\n",
    "        \n",
    "        return y_pred, y_pred_proba, self.feature_importance\n",
    "    \n",
    "    def time_series_forecasting(self):\n",
    "        \"\"\"Forecast future delay rates using time series analysis\"\"\"\n",
    "        if not TIMESERIES_AVAILABLE:\n",
    "            print(\"\\n‚ö†Ô∏è  Time series libraries not available. Skipping forecasting.\")\n",
    "            return None\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"TIME SERIES FORECASTING (30-Day Ahead)\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Aggregate daily delay rates\n",
    "        daily_delays = self.data.groupby('Order_Date')['Delivery_Status'].mean()\n",
    "        daily_delays = daily_delays.asfreq('D').fillna(method='ffill')\n",
    "        \n",
    "        # Train ARIMA model\n",
    "        try:\n",
    "            model = ARIMA(daily_delays, order=(5, 1, 2))\n",
    "            fitted_model = model.fit()\n",
    "            \n",
    "            # Forecast next 30 days\n",
    "            forecast = fitted_model.forecast(steps=30)\n",
    "            \n",
    "            print(f\"\\n‚úì ARIMA(5,1,2) model fitted\")\n",
    "            print(f\"  Current delay rate: {daily_delays.iloc[-1]*100:.2f}%\")\n",
    "            print(f\"  30-day forecast (avg): {forecast.mean()*100:.2f}%\")\n",
    "            print(f\"  Trend: {'üìà Increasing' if forecast.mean() > daily_delays.iloc[-1] else 'üìâ Decreasing'}\")\n",
    "            \n",
    "            self.forecast_results = {\n",
    "                'historical': daily_delays,\n",
    "                'forecast': forecast\n",
    "            }\n",
    "            \n",
    "            return forecast\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Forecasting error: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE 3: MULTI-OBJECTIVE OPTIMIZATION & MONTE CARLO SIMULATION\n",
    "# ============================================================================\n",
    "\n",
    "class AdvancedInventoryOptimization:\n",
    "    \"\"\"Sophisticated optimization with multiple objectives and risk quantification\"\"\"\n",
    "    \n",
    "    def __init__(self, data, model):\n",
    "        self.data = data\n",
    "        self.model = model\n",
    "        self.simulation_results = None\n",
    "        \n",
    "    def multi_objective_optimization(self):\n",
    "        \"\"\"Optimize for both cost AND service level\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"MULTI-OBJECTIVE OPTIMIZATION\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Route-level aggregation\n",
    "        routes = self.data.groupby(['Destination_Country', 'Shipping_Mode']).agg({\n",
    "            'Order_Quantity': ['mean', 'std'],\n",
    "            'Days_Real': ['mean', 'std'],\n",
    "            'Delivery_Status': 'mean',\n",
    "            'Sales_Value': 'sum',\n",
    "            'Order_ID': 'count'\n",
    "        }).reset_index()\n",
    "        \n",
    "        routes.columns = ['Country', 'Mode', 'Avg_Demand', 'Std_Demand', \n",
    "                         'Avg_LT', 'Std_LT', 'Delay_Rate', 'Total_Revenue', 'Volume']\n",
    "        \n",
    "        # Define objective function\n",
    "        def objective(service_levels, holding_cost_per_unit=0.50, stockout_penalty=0.25):\n",
    "            total_cost = 0\n",
    "            total_service = 0\n",
    "            \n",
    "            for i, sl in enumerate(service_levels):\n",
    "                z_score = stats.norm.ppf(sl)\n",
    "                route = routes.iloc[i]\n",
    "                \n",
    "                # Safety stock calculation\n",
    "                ss = z_score * np.sqrt(\n",
    "                    route['Avg_LT'] * (route['Std_Demand'] ** 2) + \n",
    "                    (route['Avg_Demand'] ** 2) * (route['Std_LT'] ** 2)\n",
    "                )\n",
    "                \n",
    "                # Holding cost\n",
    "                holding = ss * holding_cost_per_unit * 30\n",
    "                \n",
    "                # Expected stockout cost\n",
    "                stockout_prob = 1 - sl\n",
    "                stockout_cost = stockout_prob * route['Avg_Demand'] * route['Total_Revenue']/route['Volume'] * stockout_penalty\n",
    "                \n",
    "                total_cost += holding + stockout_cost\n",
    "                total_service += sl * route['Volume']\n",
    "            \n",
    "            # Multi-objective: minimize cost while maximizing service\n",
    "            # Weight: 70% cost, 30% service level\n",
    "            return 0.7 * total_cost - 0.3 * total_service\n",
    "        \n",
    "        # Constraints: service level between 0.85 and 0.99\n",
    "        bounds = [(0.85, 0.99) for _ in range(len(routes))]\n",
    "        initial_guess = [0.95] * len(routes)\n",
    "        \n",
    "        print(\"\\nüîç Running constrained optimization...\")\n",
    "        result = minimize(objective, initial_guess, method='L-BFGS-B', bounds=bounds)\n",
    "        \n",
    "        routes['Optimal_Service_Level'] = result.x\n",
    "        routes['Service_Level_Category'] = pd.cut(routes['Optimal_Service_Level'], \n",
    "                                                   bins=[0.84, 0.90, 0.95, 1.0],\n",
    "                                                   labels=['Standard', 'Enhanced', 'Premium'])\n",
    "        \n",
    "        print(f\"\\n‚úì Optimization converged: {result.success}\")\n",
    "        print(f\"  Objective value: {result.fun:,.2f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(\"OPTIMIZED SERVICE LEVELS (Top 10 Routes by Revenue)\")\n",
    "        print(\"-\" * 80)\n",
    "        display = routes.nlargest(10, 'Total_Revenue')[['Country', 'Mode', 'Delay_Rate', \n",
    "                                                         'Optimal_Service_Level', 'Service_Level_Category']]\n",
    "        print(display.to_string(index=False))\n",
    "        \n",
    "        return routes\n",
    "    \n",
    "    def monte_carlo_risk_simulation(self, n_simulations=10000):\n",
    "        \"\"\"Monte Carlo simulation for risk quantification\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"MONTE CARLO SIMULATION ({n_simulations:,} iterations)\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Select high-risk route for simulation\n",
    "        high_risk_route = self.data[self.data['Delivery_Status'] == 1].groupby(\n",
    "            ['Destination_Country', 'Shipping_Mode']\n",
    "        ).size().idxmax()\n",
    "        \n",
    "        route_data = self.data[\n",
    "            (self.data['Destination_Country'] == high_risk_route[0]) & \n",
    "            (self.data['Shipping_Mode'] == high_risk_route[1])\n",
    "        ]\n",
    "        \n",
    "        avg_demand = route_data['Order_Quantity'].mean()\n",
    "        std_demand = route_data['Order_Quantity'].std()\n",
    "        avg_lt = route_data['Days_Real'].mean()\n",
    "        std_lt = route_data['Days_Real'].std()\n",
    "        \n",
    "        print(f\"\\nüìç Simulating route: {high_risk_route[0]} - {high_risk_route[1]}\")\n",
    "        print(f\"   Historical avg demand: {avg_demand:.1f} units\")\n",
    "        print(f\"   Historical avg lead time: {avg_lt:.1f} days\")\n",
    "        \n",
    "        # Run simulation\n",
    "        np.random.seed(42)\n",
    "        stockout_events = []\n",
    "        inventory_costs = []\n",
    "        \n",
    "        safety_stock = 50  # Initial guess\n",
    "        \n",
    "        for _ in range(n_simulations):\n",
    "            # Simulate demand and lead time\n",
    "            demand = np.random.normal(avg_demand, std_demand)\n",
    "            lead_time = np.random.normal(avg_lt, std_lt)\n",
    "            \n",
    "            # Total demand during lead time\n",
    "            lead_time_demand = demand * (lead_time / 7)\n",
    "            \n",
    "            # Check if stockout occurs\n",
    "            if lead_time_demand > safety_stock:\n",
    "                stockout_events.append(1)\n",
    "            else:\n",
    "                stockout_events.append(0)\n",
    "            \n",
    "            # Calculate holding cost\n",
    "            inventory_costs.append(safety_stock * 0.50 * 30)\n",
    "        \n",
    "        stockout_probability = np.mean(stockout_events)\n",
    "        avg_inventory_cost = np.mean(inventory_costs)\n",
    "        \n",
    "        # Value at Risk (VaR) - 95th percentile\n",
    "        var_95 = np.percentile(inventory_costs, 95)\n",
    "        \n",
    "        print(f\"\\nüìä Simulation Results:\")\n",
    "        print(f\"   Stockout probability: {stockout_probability*100:.2f}%\")\n",
    "        print(f\"   Average monthly holding cost: ${avg_inventory_cost:,.2f}\")\n",
    "        print(f\"   VaR (95%): ${var_95:,.2f}\")\n",
    "        print(f\"   Recommended safety stock: {safety_stock} units\")\n",
    "        \n",
    "        self.simulation_results = {\n",
    "            'stockout_prob': stockout_probability,\n",
    "            'avg_cost': avg_inventory_cost,\n",
    "            'var_95': var_95,\n",
    "            'stockout_events': stockout_events,\n",
    "            'inventory_costs': inventory_costs\n",
    "        }\n",
    "        \n",
    "        return self.simulation_results\n",
    "    \n",
    "    def scenario_analysis(self):\n",
    "        \"\"\"What-if analysis for different disruption scenarios\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"SCENARIO ANALYSIS - DISRUPTION IMPACT MODELING\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        scenarios = {\n",
    "            'Baseline': {'delay_increase': 0, 'cost_increase': 0},\n",
    "            'Mild_Disruption': {'delay_increase': 0.15, 'cost_increase': 0.10},\n",
    "            'Moderate_Disruption': {'delay_increase': 0.30, 'cost_increase': 0.25},\n",
    "            'Severe_Disruption': {'delay_increase': 0.50, 'cost_increase': 0.50},\n",
    "            'Black_Swan': {'delay_increase': 1.00, 'cost_increase': 1.00}\n",
    "        }\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for scenario_name, params in scenarios.items():\n",
    "            # Simulate scenario impact\n",
    "            simulated_delays = self.data['Delay_Days'].copy()\n",
    "            simulated_costs = self.data['Transport_Cost'].copy()\n",
    "            \n",
    "            # Apply scenario multipliers\n",
    "            simulated_delays = simulated_delays * (1 + params['delay_increase'])\n",
    "            simulated_costs = simulated_costs * (1 + params['cost_increase'])\n",
    "            \n",
    "            # Calculate metrics\n",
    "            avg_delay = simulated_delays.mean()\n",
    "            total_cost = simulated_costs.sum()\n",
    "            delay_rate = ((self.data['Days_Scheduled'] + simulated_delays) > self.data['Days_Scheduled']).mean()\n",
    "            \n",
    "            # Revenue impact (assuming 5% revenue loss per day of delay)\n",
    "            revenue_impact = self.data['Sales_Value'].sum() * (avg_delay / 10) * 0.05\n",
    "            \n",
    "            results.append({\n",
    "                'Scenario': scenario_name,\n",
    "                'Avg_Delay_Days': avg_delay,\n",
    "                'Total_Transport_Cost': total_cost,\n",
    "                'Delay_Rate': delay_rate * 100,\n",
    "                'Revenue_Impact': revenue_impact,\n",
    "                'Total_Impact': total_cost + revenue_impact\n",
    "            })\n",
    "        \n",
    "        scenario_df = pd.DataFrame(results)\n",
    "        \n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(\"SCENARIO COMPARISON\")\n",
    "        print(\"-\" * 80)\n",
    "        print(scenario_df.to_string(index=False))\n",
    "        \n",
    "        # Risk-adjusted recommendation\n",
    "        print(\"\\nüí° STRATEGIC RECOMMENDATIONS:\")\n",
    "        moderate_impact = scenario_df[scenario_df['Scenario'] == 'Moderate_Disruption']['Total_Impact'].values[0]\n",
    "        baseline_impact = scenario_df[scenario_df['Scenario'] == 'Baseline']['Total_Impact'].values[0]\n",
    "        \n",
    "        risk_premium = moderate_impact - baseline_impact\n",
    "        \n",
    "        print(f\"\\n   Risk Premium (Moderate Disruption): ${risk_premium:,.2f}\")\n",
    "        print(f\"   Recommended contingency budget: ${risk_premium * 0.3:,.2f} (30% of risk premium)\")\n",
    "        print(f\"\\n   Priority Actions:\")\n",
    "        print(f\"   1. Build safety stock for routes with >40% delay probability\")\n",
    "        print(f\"   2. Diversify suppliers in high-risk regions\")\n",
    "        print(f\"   3. Establish alternate shipping modes for critical shipments\")\n",
    "        \n",
    "        return scenario_df\n",
    "    \n",
    "    def supplier_diversification_analysis(self):\n",
    "        \"\"\"Recommend supplier diversification to reduce concentration risk\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"SUPPLIER DIVERSIFICATION STRATEGY\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Calculate supplier concentration\n",
    "        supplier_analysis = self.data.groupby('Supplier_ID').agg({\n",
    "            'Sales_Value': 'sum',\n",
    "            'Order_ID': 'count',\n",
    "            'Delivery_Status': 'mean',\n",
    "            'Delay_Days': 'mean'\n",
    "        }).reset_index()\n",
    "        \n",
    "        supplier_analysis.columns = ['Supplier_ID', 'Total_Revenue', 'Order_Count', 'Delay_Rate', 'Avg_Delay']\n",
    "        supplier_analysis['Revenue_Share'] = (supplier_analysis['Total_Revenue'] / supplier_analysis['Total_Revenue'].sum()) * 100\n",
    "        \n",
    "        # Herfindahl-Hirschman Index (HHI) for concentration\n",
    "        hhi = (supplier_analysis['Revenue_Share'] ** 2).sum()\n",
    "        \n",
    "        print(f\"\\nüìä Supplier Concentration Metrics:\")\n",
    "        print(f\"   Total suppliers: {len(supplier_analysis)}\")\n",
    "        print(f\"   HHI Score: {hhi:.2f} (>2500 = highly concentrated)\")\n",
    "        \n",
    "        if hhi > 2500:\n",
    "            concentration_level = \"‚ö†Ô∏è  HIGH - Significant concentration risk\"\n",
    "        elif hhi > 1500:\n",
    "            concentration_level = \"‚ö° MODERATE - Some concentration risk\"\n",
    "        else:\n",
    "            concentration_level = \"‚úÖ LOW - Well diversified\"\n",
    "        \n",
    "        print(f\"   Concentration Level: {concentration_level}\")\n",
    "        \n",
    "        # Top 5 suppliers\n",
    "        top_suppliers = supplier_analysis.nlargest(5, 'Revenue_Share')\n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(\"TOP 5 SUPPLIERS (by Revenue)\")\n",
    "        print(\"-\" * 80)\n",
    "        print(top_suppliers[['Supplier_ID', 'Revenue_Share', 'Delay_Rate', 'Avg_Delay']].to_string(index=False))\n",
    "        \n",
    "        # Identify high-risk, high-dependency suppliers\n",
    "        top_suppliers['Risk_Score'] = top_suppliers['Revenue_Share'] * top_suppliers['Delay_Rate'] * 100\n",
    "        high_risk_suppliers = top_suppliers[top_suppliers['Risk_Score'] > 50]\n",
    "        \n",
    "        if len(high_risk_suppliers) > 0:\n",
    "            print(f\"\\nüö® HIGH-RISK SUPPLIERS (high dependency + high delays):\")\n",
    "            for _, row in high_risk_suppliers.iterrows():\n",
    "                print(f\"   {row['Supplier_ID']}: {row['Revenue_Share']:.1f}% revenue, {row['Delay_Rate']*100:.1f}% delays\")\n",
    "            \n",
    "            print(f\"\\n   Recommendation: Reduce dependency on these suppliers by 30-50%\")\n",
    "        \n",
    "        return supplier_analysis\n",
    "# ============================================================================\n",
    "# ADVANCED VISUALIZATION & REPORTING\n",
    "# ============================================================================\n",
    "\n",
    "class AdvancedVisualization:\n",
    "    \"\"\"Comprehensive visualization suite\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def create_executive_dashboard(data, model, feature_importance, scenario_df):\n",
    "        fig = plt.figure(figsize=(20, 12))\n",
    "        gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "\n",
    "        # 1. Weekly delay trend\n",
    "        ax1 = fig.add_subplot(gs[0, 0:2])\n",
    "        weekly_delays = data.groupby(\n",
    "            data['Order_Date'].dt.to_period('W')\n",
    "        )['Delivery_Status'].mean()\n",
    "        ax1.plot(weekly_delays.index.astype(str), weekly_delays.values, linewidth=2)\n",
    "        ax1.set_title('Weekly Delay Rate Trend', fontweight='bold')\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        ax1.grid(alpha=0.3)\n",
    "\n",
    "        # 2. Country risk\n",
    "        ax2 = fig.add_subplot(gs[0, 2:4])\n",
    "        geo_risk = (\n",
    "            data.groupby('Destination_Country')['Delivery_Status']\n",
    "            .mean()\n",
    "            .sort_values(ascending=False)\n",
    "            .head(10)\n",
    "        )\n",
    "        ax2.barh(geo_risk.index, geo_risk.values)\n",
    "        ax2.set_title('Top 10 Countries by Delay Rate', fontweight='bold')\n",
    "\n",
    "        # 3. Feature importance\n",
    "        ax3 = fig.add_subplot(gs[1, 0:2])\n",
    "        top_features = feature_importance.head(10)\n",
    "        ax3.barh(top_features['Feature'], top_features['Importance'])\n",
    "        ax3.set_title('Top Predictive Features', fontweight='bold')\n",
    "        ax3.invert_yaxis()\n",
    "\n",
    "        # 4. Scenario impact\n",
    "        ax4 = fig.add_subplot(gs[1, 2:4])\n",
    "        ax4.bar(\n",
    "            scenario_df['Scenario'],\n",
    "            scenario_df['Total_Impact'] / 1e6\n",
    "        )\n",
    "        ax4.set_title('Scenario Impact ($M)', fontweight='bold')\n",
    "        ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "        # 5. Shipping mode performance\n",
    "        ax5 = fig.add_subplot(gs[2, 0])\n",
    "        mode_perf = data.groupby('Shipping_Mode')['Delivery_Status'].mean()\n",
    "        ax5.bar(mode_perf.index, mode_perf.values * 100)\n",
    "        ax5.set_title('Delay Rate by Shipping Mode')\n",
    "\n",
    "        # 6. Cost vs benefit\n",
    "        ax6 = fig.add_subplot(gs[2, 1])\n",
    "        ax6.scatter(\n",
    "            data['Transport_Cost'],\n",
    "            data['Benefit_per_Order'],\n",
    "            alpha=0.4\n",
    "        )\n",
    "        ax6.set_title('Cost vs Benefit')\n",
    "\n",
    "        # 7. Delay distribution\n",
    "        ax7 = fig.add_subplot(gs[2, 2])\n",
    "        delays = data[data['Delivery_Status'] == 1]['Delay_Days']\n",
    "        ax7.hist(delays, bins=30)\n",
    "        ax7.set_title('Delay Distribution')\n",
    "\n",
    "        # 8. Risk score distribution (SAFE)\n",
    "        ax8 = fig.add_subplot(gs[2, 3])\n",
    "        if model is not None:\n",
    "            feature_cols = [\n",
    "                'Destination_Country', 'Shipping_Mode', 'Product_Category', 'Supplier_ID',\n",
    "                'Days_Scheduled', 'Order_Quantity', 'Sales_Value', 'Transport_Cost',\n",
    "                'Route_Volatility', 'Country_Risk_Score', 'Mode_Risk_Score',\n",
    "                'Supplier_Risk_Score', 'Month', 'Quarter', 'Day_of_Week',\n",
    "                'Is_Peak_Season', 'Is_Winter', 'MA_30_Delay_Rate', 'MA_90_Delay_Rate',\n",
    "                'Value_Quantity_Ratio', 'Cost_Benefit_Ratio', 'Priority_Risk', 'EMA_Delay'\n",
    "            ]\n",
    "\n",
    "            if 'Supplier_Centrality' in data.columns:\n",
    "                feature_cols.extend(['Supplier_Centrality', 'Warehouse_Centrality'])\n",
    "\n",
    "            X_full = data[feature_cols].copy()\n",
    "\n",
    "            for col in [\n",
    "                'Destination_Country',\n",
    "                'Shipping_Mode',\n",
    "                'Product_Category',\n",
    "                'Supplier_ID'\n",
    "            ]:\n",
    "                le = LabelEncoder()\n",
    "                X_full[col] = le.fit_transform(X_full[col].astype(str))\n",
    "\n",
    "            X_full = X_full.fillna(X_full.median())\n",
    "            X_full = X_full[model.feature_names_in_]\n",
    "\n",
    "            risk_scores = model.predict_proba(X_full)[:, 1]\n",
    "            ax8.hist(risk_scores, bins=50)\n",
    "            ax8.axvline(0.5, linestyle='--', color='red')\n",
    "            ax8.set_title('Predicted Risk Score Distribution')\n",
    "\n",
    "        plt.suptitle(\n",
    "            'SUPPLY CHAIN EXECUTIVE DASHBOARD',\n",
    "            fontsize=18,\n",
    "            fontweight='bold'\n",
    "        )\n",
    "        plt.savefig(\n",
    "            'executive_dashboard.png',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight'\n",
    "        )\n",
    "        print(\"‚úì Executive dashboard saved: executive_dashboard.png\")\n",
    "        return fig\n",
    "\n",
    "    @staticmethod\n",
    "    def create_network_visualization(network):\n",
    "        fig, ax = plt.subplots(figsize=(16, 12))\n",
    "        pos = nx.spring_layout(network, seed=42)\n",
    "\n",
    "        nx.draw_networkx_nodes(network, pos, node_size=400, alpha=0.8, ax=ax)\n",
    "        nx.draw_networkx_edges(network, pos, alpha=0.4, ax=ax)\n",
    "        nx.draw_networkx_labels(network, pos, font_size=7, ax=ax)\n",
    "\n",
    "        ax.set_title('Global Supply Chain Network Topology', fontweight='bold')\n",
    "        ax.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('network_topology.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"‚úì Network visualization saved: network_topology.png\")\n",
    "        return fig\n",
    "\n",
    "    @staticmethod\n",
    "    def create_monte_carlo_visualization(simulation_results):\n",
    "        if simulation_results is None:\n",
    "            print(\"‚ö†Ô∏è No Monte Carlo results to visualize.\")\n",
    "            return None\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        costs = simulation_results['inventory_costs']\n",
    "        var_95 = simulation_results['var_95']\n",
    "        stockout_prob = simulation_results['stockout_prob']\n",
    "\n",
    "        ax.hist(costs, bins=50, alpha=0.75, edgecolor='black')\n",
    "        ax.axvline(var_95, linestyle='--', linewidth=2,\n",
    "                   label=f'VaR 95% = ${var_95:,.0f}')\n",
    "        ax.set_title('Monte Carlo Simulation ‚Äì Inventory Risk', fontweight='bold')\n",
    "        ax.set_xlabel('Monthly Holding Cost ($)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "\n",
    "        ax.text(\n",
    "            0.95, 0.95,\n",
    "            f\"Stockout Probability: {stockout_prob*100:.2f}%\",\n",
    "            transform=ax.transAxes,\n",
    "            ha='right', va='top',\n",
    "            bbox=dict(facecolor='white', alpha=0.8)\n",
    "        )\n",
    "\n",
    "        ax.legend()\n",
    "        ax.grid(alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('monte_carlo_simulation.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"‚úì Monte Carlo visualization saved: monte_carlo_simulation.png\")\n",
    "        return fig\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION PIPELINE - ADVANCED VERSION\n",
    "# ============================================================================\n",
    "\n",
    "def main_advanced():\n",
    "    \"\"\"Execute comprehensive advanced supply chain analysis\"\"\"\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"‚ïî\" + \"=\" * 78 + \"‚ïó\")\n",
    "    print(\"‚ïë\" + \" \" * 78 + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \"  ADVANCED SUPPLY CHAIN RESILIENCE & DISRUPTION MODELING\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \"  Enterprise-Grade Predictive & Prescriptive Analytics\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \" \" * 78 + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \"  New Features:\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \"  ‚Ä¢ Multi-objective optimization\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \"  ‚Ä¢ Monte Carlo risk simulation\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \"  ‚Ä¢ Network topology analysis\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \"  ‚Ä¢ Time series forecasting\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \"  ‚Ä¢ Scenario analysis\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \"  ‚Ä¢ Supplier diversification strategy\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \" \" * 78 + \"‚ïë\")\n",
    "    print(\"‚ïö\" + \"=\" * 78 + \"‚ïù\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # ========== PHASE 1: ADVANCED DATA ENGINEERING ==========\n",
    "    print(\"\\nüîß PHASE 1: Advanced Data Engineering & Network Analysis\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    kaggle_path = '/kaggle/input/us-data/data (1).csv' \n",
    "    engineer = AdvancedSupplyChainDataEngineer()\n",
    "    data = engineer.load_and_map_data(kaggle_path)\n",
    "    network = engineer.build_supply_chain_network()\n",
    "    data = engineer.engineer_advanced_features()\n",
    "    anomalies = engineer.detect_anomalies()\n",
    "    \n",
    "    # ========== PHASE 2: ADVANCED PREDICTIVE MODELING ==========\n",
    "    print(\"\\nü§ñ PHASE 2: Advanced Predictive Modeling & Forecasting\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    predictor = AdvancedPredictiveModeling(data)\n",
    "    predictor.prepare_modeling_data()\n",
    "    predictor.train_with_hyperparameter_tuning()\n",
    "    y_pred, y_pred_proba, feature_importance = predictor.advanced_model_evaluation()\n",
    "    forecast = predictor.time_series_forecasting()\n",
    "    \n",
    "    # ========== PHASE 3: ADVANCED OPTIMIZATION ==========\n",
    "    print(\"\\nüí° PHASE 3: Multi-Objective Optimization & Risk Simulation\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    optimizer = AdvancedInventoryOptimization(data, predictor.model)\n",
    "    optimized_routes = optimizer.multi_objective_optimization()\n",
    "    simulation_results = optimizer.monte_carlo_risk_simulation(n_simulations=10000)\n",
    "    scenario_df = optimizer.scenario_analysis()\n",
    "    supplier_analysis = optimizer.supplier_diversification_analysis()\n",
    "    \n",
    "    # ========== PHASE 4: ADVANCED VISUALIZATION ==========\n",
    "    print(\"\\nüìä PHASE 4: Advanced Visualization & Reporting\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    viz = AdvancedVisualization()\n",
    "    viz.create_executive_dashboard(data, predictor.model, feature_importance, scenario_df)\n",
    "    viz.create_network_visualization(network)\n",
    "    viz.create_monte_carlo_visualization(simulation_results)\n",
    "    \n",
    "    # ========== FINAL SUMMARY ==========\n",
    "    print(\"\\n\")\n",
    "    print(\"‚ïî\" + \"=\" * 78 + \"‚ïó\")\n",
    "    print(\"‚ïë\" + \" \" * 78 + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \"  ADVANCED ANALYSIS COMPLETE\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \" \" * 78 + \"‚ïë\")\n",
    "    print(\"‚ïë\" + f\"  Records Analyzed: {len(data):,}\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + f\"  Time Period: {data['Order_Date'].min().date()} to {data['Order_Date'].max().date()}\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + f\"  Model Performance (ROC-AUC): {roc_auc_score(predictor.y_test, y_pred_proba):.4f}\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + f\"  Network Nodes: {network.number_of_nodes()}  |  Edges: {network.number_of_edges()}\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + f\"  Anomalies Detected: {len(anomalies)} ({len(anomalies)/len(data)*100:.2f}%)\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \" \" * 78 + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \"  Generated Outputs:\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \"    ‚Ä¢ executive_dashboard.png (8-panel comprehensive view)\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \"    ‚Ä¢ network_topology.png (supply chain graph)\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \"    ‚Ä¢ monte_carlo_simulation.png (risk quantification)\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \" \" * 78 + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \"  CSV Exports:\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \"    ‚Ä¢ supply_chain_advanced_data.csv\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \"    ‚Ä¢ optimized_routes.csv\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \"    ‚Ä¢ scenario_analysis.csv\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \"    ‚Ä¢ supplier_analysis.csv\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \"    ‚Ä¢ feature_importance.csv\".center(78) + \"‚ïë\")\n",
    "    print(\"‚ïë\" + \" \" * 78 + \"‚ïë\")\n",
    "    print(\"‚ïö\" + \"=\" * 78 + \"‚ïù\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Export results\n",
    "    print(\"üìÅ Exporting results to CSV files...\")\n",
    "    data.to_csv('supply_chain_advanced_data.csv', index=False)\n",
    "    optimized_routes.to_csv('optimized_routes.csv', index=False)\n",
    "    scenario_df.to_csv('scenario_analysis.csv', index=False)\n",
    "    supplier_analysis.to_csv('supplier_analysis.csv', index=False)\n",
    "    feature_importance.to_csv('feature_importance.csv', index=False)\n",
    "    print(\"‚úì All results exported successfully\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ ALL PHASES COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nThis analysis is ready for:\")\n",
    "    print(\"  ‚Ä¢ C-suite presentations\")\n",
    "    print(\"  ‚Ä¢ Academic portfolio submissions\")\n",
    "    print(\"  ‚Ä¢ Consulting case interviews\")\n",
    "    print(\"  ‚Ä¢ Technical deep-dives with stakeholders\")\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    \n",
    "    return {\n",
    "        'data': data,\n",
    "        'network': network,\n",
    "        'model': predictor.model,\n",
    "        'feature_importance': feature_importance,\n",
    "        'optimized_routes': optimized_routes,\n",
    "        'simulation_results': simulation_results,\n",
    "        'scenario_analysis': scenario_df,\n",
    "        'supplier_analysis': supplier_analysis,\n",
    "        'anomalies': anomalies\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main_advanced()\n",
    "    import io\n",
    "    from contextlib import redirect_stdout\n",
    "\n",
    "    output_buffer = io.StringIO()\n",
    "\n",
    "    with redirect_stdout(output_buffer):\n",
    "        results = main_advanced()\n",
    "\n",
    "    full_text_report = output_buffer.getvalue()\n",
    "\n",
    "    print(\"Captured characters:\", len(full_text_report))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"\\nüéØ Next steps:\")\n",
    "    print(\"  1. Review executive_dashboard.png for key insights\")\n",
    "    print(\"  2. Examine CSV exports for detailed data\")\n",
    "    print(\"  3. Use scenario_analysis.csv for strategic planning\")\n",
    "    print(\"  4. Share network_topology.png to visualize dependencies\")\n",
    "    print(\"  5. Present monte_carlo_simulation.png for risk discussions\")\n",
    "    print(\"\\n‚ú® Analysis complete - ready for stakeholder presentation!\")\n",
    "\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30909449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "\n",
    "def render_text_page(lines, start, lines_per_page=55):\n",
    "    fig = plt.figure(figsize=(8.27, 11.69))  # A4\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    page_lines = lines[start:start + lines_per_page]\n",
    "    wrapped = []\n",
    "    for line in page_lines:\n",
    "        wrapped.extend(textwrap.wrap(line, width=110) or [\" \"])\n",
    "\n",
    "    plt.text(\n",
    "        0.01, 0.99,\n",
    "        \"\\n\".join(wrapped),\n",
    "        va=\"top\",\n",
    "        ha=\"left\",\n",
    "        family=\"monospace\",\n",
    "        fontsize=9\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "pdf_path = \"/kaggle/working/supply_chain_full_execution_report.pdf\"\n",
    "\n",
    "with PdfPages(pdf_path) as pdf:\n",
    "\n",
    "    # TEXT PAGES\n",
    "    lines = full_text_report.split(\"\\n\")\n",
    "    for i in range(0, len(lines), 55):\n",
    "        fig = render_text_page(lines, i)\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "    # FIGURE PAGES\n",
    "    viz = AdvancedVisualization()\n",
    "\n",
    "    fig1 = viz.create_executive_dashboard(\n",
    "        results['data'],\n",
    "        results['model'],\n",
    "        results['feature_importance'],\n",
    "        results['scenario_analysis']\n",
    "    )\n",
    "    pdf.savefig(fig1)\n",
    "    plt.close(fig1)\n",
    "\n",
    "    fig2 = viz.create_network_visualization(results['network'])\n",
    "    pdf.savefig(fig2)\n",
    "    plt.close(fig2)\n",
    "\n",
    "    fig3 = viz.create_monte_carlo_visualization(results['simulation_results'])\n",
    "    if fig3:\n",
    "        pdf.savefig(fig3)\n",
    "        plt.close(fig3)\n",
    "\n",
    "print(\"‚úì PDF saved at:\", pdf_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
